# -*- coding: utf-8 -*-
"""Copy of project1.pynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z4eNRBtbKVK-KFswfQvUCLsWPIQM4l8u

# Big Sales Prediction using Random Forest Regressor

**Objectives**

The objective of this project is to predict the sales based on historical data using machine learning, specifically with a Random Forest Regressor. We will analyze sales trends and develop a model that can forecast future sales for better business decision-making.

**Data Source**

Dataset provided with the following columns: Item, weight, fat content, visibility, type, MRP, outlet, and sales information.

**Import Library**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

"""**Import Data**

"""

# Load the dataset
url = r'https://raw.githubusercontent.com/YBI-Foundation/Dataset/main/Big%20Sales%20Data.csv'
data = pd.read_csv(url)

# Display the first few rows
print(data.head())

"""**Describe Data**"""

# Get an overview of the dataset
print(data.info())
print(data.describe())

"""**Data Visualization**

"""

correlation_matrix = data.corr()

# Plot the heatmap
plt.figure(figsize=(10, 8))  # Set the figure size
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')  # Create the heatmap with annotations
plt.title('Correlation Heatmap')  # Set the title of the plot
plt.show()  # Display the plot

"""**Data Preprocessing**"""

# Check for missing values
print(data.isnull().sum())

# Fill missing values for 'Item_Weight' (example strategy)
data['Item_Weight'].fillna(data['Item_Weight'].mean(), inplace=True)

# Convert categorical variables into dummy/indicator variables
data = pd.get_dummies(data, drop_first=True)

"""**Define Target Variable (y) and Feature Variables (X)**"""

# Target variable (y) - 'Item_Outlet_Sales'
y = data['Item_Outlet_Sales']

# Feature variables (X) - drop 'Item_Outlet_Sales' from features
X = data.drop('Item_Outlet_Sales', axis=1)

"""**Train Test Split**"""

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Train set shape: ", X_train.shape)
print("Test set shape: ", X_test.shape)

"""**Modeling**"""

# Initialize the Random Forest Regressor
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)

# Fit the model on the training data
rf_model.fit(X_train, y_train)

"""**Model Evaluation**"""

# Predict on the test set
y_pred = rf_model.predict(X_test)

# Calculate and print the RMSE (Root Mean Squared Error)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
print(f'Root Mean Squared Error: {rmse}')

"""**Prediction**"""

# Example prediction for new data (if available)
# Let's assume new_data is a new observation to predict sales
# new_data = [...]  # replace with new observation data
# prediction = rf_model.predict([new_data])
# print(f'Predicted Sales: {prediction}')

"""**Explaination**

In this project, we used the Random Forest Regressor model to predict item outlet sales based on historical data. The model was evaluated using Root Mean Squared Error (RMSE), which gives us an idea of how well the model performs in predicting sales. Further steps could include hyperparameter tuning and model deployment.
"""